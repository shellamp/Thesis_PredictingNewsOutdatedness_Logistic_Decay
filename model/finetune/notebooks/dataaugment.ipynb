{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d195b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Loading translation pipelines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use mps:0\n",
      "Device set to use mps:0\n",
      "üîÅ Back-translating dummy data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:19<00:00,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Final back-translated dummy dataset:\n",
      "\n",
      "üì∞ Article 1:\n",
      "BT: Climate change is accelerating. New reports show that global temperatures are rising faster than expected.\n",
      "\n",
      "üì∞ Article 2:\n",
      "BT: Electric cars are gaining popularity in Europe. In 2024, the sale of electric vehicles reached a new record.\n",
      "\n",
      "üì∞ Article 3:\n",
      "BT: AI tools change our way of working. Companies take over generative AI to improve productivity and automate tasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "INPUT_PATH = Path(\"/content/drive/MyDrive/final/Thesis/data/augment/train_balanced.json\")\n",
    "OUTPUT_PATH = Path(\"/content/drive/MyDrive/final/Thesis/data/augment/train_balanced_plus_bt.json\")\n",
    "\n",
    "with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"üìÅ Loaded {len(data)} articles\")\n",
    "\n",
    "print(\"üîÅ Loading translation models...\")\n",
    "en_to_de = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-de\", device=0)\n",
    "de_to_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-de-en\", device=0)\n",
    "\n",
    "\n",
    "for article_id, article in tqdm(data.items(), desc=\"üîÅ Back-translating label==1 only\"):\n",
    "    if article.get(\"label\") != 1:\n",
    "        continue \n",
    "\n",
    "    title = article.get(\"title_normalized\", \"\")\n",
    "    summary = article.get(\"summary_normalized\", \"\")\n",
    "\n",
    "    try:\n",
    "        title_de = en_to_de(title, max_length=512)[0][\"translation_text\"]\n",
    "        summary_de = en_to_de(summary, max_length=512)[0][\"translation_text\"]\n",
    "\n",
    "        title_bt = de_to_en(title_de, max_length=512)[0][\"translation_text\"]\n",
    "        summary_bt = de_to_en(summary_de, max_length=512)[0][\"translation_text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error for article {article_id}: {e}\")\n",
    "        title_bt = title\n",
    "        summary_bt = summary\n",
    "\n",
    "    article[\"bt\"] = f\"{title_bt}. {summary_bt}\"\n",
    "\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Back-translated dataset saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f85a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ Original articles: 996\n",
      "üü† Synthetic articles: 498\n",
      "üì¶ Final merged total: 1494\n",
      "‚úÖ Output saved to: /Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_Logistic_Decay/model/finetune/data/train_balanced_plus_bt_separated.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIG ===\n",
    "INPUT_PATH = Path(\"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_Logistic_Decay/model/finetune/data/train_balanced_plus_bt.json\")\n",
    "OUTPUT_PATH = Path(\"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_Logistic_Decay/model/finetune/data/train_balanced_plus_bt_separated.json\")\n",
    "\n",
    "# === LOAD DATA ===\n",
    "with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "original_articles = {}\n",
    "synthetic_articles = {}\n",
    "id_counter = max(int(k) for k in data.keys()) + 1  # To generate new unique keys\n",
    "\n",
    "for key, article in data.items():\n",
    "    # Make a copy of the article for original and synthetic\n",
    "    original = article.copy()\n",
    "    synthetic = article.copy()\n",
    "\n",
    "    # If article has a back-translated version\n",
    "    if \"bt\" in article and article[\"bt\"]:\n",
    "        # 1. Add the original version without the \"bt\" field\n",
    "        original.pop(\"bt\", None)\n",
    "        original_articles[key] = original\n",
    "\n",
    "        # 2. Create a synthetic version (same fields + \"bt\")\n",
    "        synthetic_articles[str(id_counter)] = synthetic\n",
    "        id_counter += 1\n",
    "    else:\n",
    "        # No \"bt\" ‚Üí keep the original as is\n",
    "        original_articles[key] = article\n",
    "\n",
    "# === COMBINE ORIGINAL + SYNTHETIC ===\n",
    "final_data = {**original_articles, **synthetic_articles}\n",
    "print(f\"üü¢ Original articles: {len(original_articles)}\")\n",
    "print(f\"üü† Synthetic articles: {len(synthetic_articles)}\")\n",
    "print(f\"üì¶ Final merged total: {len(final_data)}\")\n",
    "\n",
    "# === SAVE TO OUTPUT FILE ===\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Output saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74d9aa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total merged articles: 2729\n",
      "‚öñÔ∏è  Balancing to 991 samples per class\n",
      "üìÅ Saved balanced training set: /Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_Logistic_Decay/model/finetune/data/train_ready_balanced.json (1982 samples)\n",
      "üìÅ Saved remainder data: /Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_Logistic_Decay/model/finetune/data/train_remainder.json (747 samples)\n",
      "üìä Final label distribution in training: Counter({0: 991, 1: 991})\n",
      "üìä Remaining data label distribution: Counter({0: 747})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# === CONFIG ===\n",
    "BT_PATH = Path(\"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_Logistic_Decay/model/finetune/data/train_balanced_plus_bt_separated.json\")\n",
    "REMAINING_PATH = Path(\"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_Logistic_Decay/model/finetune/data/remaining_majority_not_in_seed.json\")\n",
    "BALANCED_OUTPUT = Path(\"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_Logistic_Decay/model/finetune/data/train_ready_balanced.json\")\n",
    "REMAINDER_OUTPUT = Path(\"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_Logistic_Decay/model/finetune/data/train_remainder.json\")\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# === LOAD FILES ===\n",
    "with open(BT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    bt_data = json.load(f)\n",
    "\n",
    "with open(REMAINING_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    remaining_data = json.load(f)\n",
    "\n",
    "# === MERGE DATA ===\n",
    "merged_data = {**bt_data, **remaining_data}\n",
    "print(f\"‚úÖ Total merged articles: {len(merged_data)}\")\n",
    "\n",
    "# === GROUP BY LABEL ===\n",
    "label_groups = {0: [], 1: []}\n",
    "for k, v in merged_data.items():\n",
    "    label = v.get(\"label\")\n",
    "    if label in [0, 1]:\n",
    "        label_groups[label].append((k, v))\n",
    "\n",
    "# === BALANCE DATA ===\n",
    "min_count = min(len(label_groups[0]), len(label_groups[1]))\n",
    "print(f\"‚öñÔ∏è  Balancing to {min_count} samples per class\")\n",
    "\n",
    "balanced_data = {}\n",
    "remainder_data = {}\n",
    "\n",
    "for label in [0, 1]:\n",
    "    selected = random.sample(label_groups[label], min_count)\n",
    "    not_selected = [item for item in label_groups[label] if item not in selected]\n",
    "\n",
    "    # Add to output\n",
    "    for k, v in selected:\n",
    "        balanced_data[k] = v\n",
    "    for k, v in not_selected:\n",
    "        remainder_data[k] = v\n",
    "\n",
    "# === SAVE BALANCED TRAINING DATA ===\n",
    "with open(BALANCED_OUTPUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(balanced_data, f, indent=2, ensure_ascii=False)\n",
    "print(f\"üìÅ Saved balanced training set: {BALANCED_OUTPUT} ({len(balanced_data)} samples)\")\n",
    "\n",
    "# === SAVE REMAINDER ===\n",
    "with open(REMAINDER_OUTPUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(remainder_data, f, indent=2, ensure_ascii=False)\n",
    "print(f\"üìÅ Saved remainder data: {REMAINDER_OUTPUT} ({len(remainder_data)} samples)\")\n",
    "\n",
    "# === STATS ===\n",
    "balanced_labels = [v[\"label\"] for v in balanced_data.values()]\n",
    "remainder_labels = [v[\"label\"] for v in remainder_data.values()]\n",
    "print(f\"üìä Final label distribution in training: {Counter(balanced_labels)}\")\n",
    "print(f\"üìä Remaining data label distribution: {Counter(remainder_labels)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
