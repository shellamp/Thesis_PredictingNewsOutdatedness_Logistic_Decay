{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "116374cd",
   "metadata": {},
   "source": [
    "Summary Count of each Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28ce64af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š === Label Summary ===\n",
      "Total articles: 9577\n",
      "Label 0: 0\n",
      "Label 1: 0\n",
      "No label: 9577\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_PATH = Path(\"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/probability/probability.json\")\n",
    "\n",
    "def load_json(file_path: Path) -> dict:\n",
    "    \"\"\"Load JSON file and return as dict.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def summarize_labels(data: dict) -> dict:\n",
    "    \"\"\"Count labels 0, 1, and None in dataset.\"\"\"\n",
    "    total = len(data)\n",
    "    count_0 = sum(1 for v in data.values() if v.get(\"label\") == 0)\n",
    "    count_1 = sum(1 for v in data.values() if v.get(\"label\") == 1)\n",
    "    count_none = sum(1 for v in data.values() if v.get(\"label\") not in [0, 1])\n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"label_0\": count_0,\n",
    "        \"label_1\": count_1,\n",
    "        \"label_none\": count_none\n",
    "    }\n",
    "\n",
    "def print_summary(summary: dict) -> None:\n",
    "    \"\"\"Nicely print the label summary.\"\"\"\n",
    "    print(\"ðŸ“Š === Label Summary ===\")\n",
    "    print(f\"Total articles: {summary['total']}\")\n",
    "    print(f\"Label 0: {summary['label_0']}\")\n",
    "    print(f\"Label 1: {summary['label_1']}\")\n",
    "    print(f\"No label: {summary['label_none']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_json(INPUT_PATH)\n",
    "    summary = summarize_labels(data)\n",
    "    print_summary(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced2492",
   "metadata": {},
   "source": [
    "JSON to XLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4cf05e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Detected format: index (dict of dicts)\n",
      "âœ… Excel saved to: /Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/main_dataset.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "JSON_PATH = Path(\"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/main_dataset.json\")\n",
    "EXCEL_PATH = JSON_PATH.with_suffix(\".xlsx\")\n",
    "\n",
    "def load_json(file_path: Path) -> dict | list:\n",
    "    \"\"\"Load JSON file and return as dict or list.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def json_to_dataframe(data: dict | list) -> pd.DataFrame:\n",
    "    \"\"\"Convert JSON data to DataFrame, auto-detecting format.\"\"\"\n",
    "    if isinstance(data, list):\n",
    "        print(\"ðŸ” Detected format: records (list of dicts)\")\n",
    "        return pd.DataFrame(data)\n",
    "    elif isinstance(data, dict):\n",
    "        print(\"ðŸ” Detected format: index (dict of dicts)\")\n",
    "        df = pd.DataFrame.from_dict(data, orient=\"index\").reset_index()\n",
    "        df = df.rename(columns={\"index\": \"article_id\"})\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported JSON structure. Must be list or dict.\")\n",
    "\n",
    "def save_dataframe_to_excel(df: pd.DataFrame, file_path: Path) -> None:\n",
    "    \"\"\"Save DataFrame to Excel.\"\"\"\n",
    "    df.to_excel(file_path, index=False)\n",
    "    print(f\"âœ… Excel saved to: {file_path}\")\n",
    "\n",
    "def save_dataframe_to_json(df: pd.DataFrame, file_path: Path) -> None:\n",
    "    \"\"\"Optionally save DataFrame back to JSON if needed.\"\"\"\n",
    "    data = df.to_dict(orient=\"records\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"âœ… JSON saved to: {file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_json(JSON_PATH)\n",
    "    df = json_to_dataframe(data)\n",
    "    save_dataframe_to_excel(df, EXCEL_PATH)\n",
    "    # Optional: save the same DataFrame back to JSON (records format)\n",
    "    # save_dataframe_to_json(df, JSON_PATH.with_stem(JSON_PATH.stem + \"_records\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954f40b",
   "metadata": {},
   "source": [
    "XLS to JSOn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c72e8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… JSON restored and saved to: /Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/main_dataset.json\n",
      "ðŸ”‘ Total articles: 12477\n",
      "ðŸ“„ Fields in each article: ['article_id', 'source', 'url', 'date', 'title', 'body', 'summary', 'category', 'title_normalized', 'summary_normalized', 't', 't_bin']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIG ===\n",
    "EXCEL_PATH = Path(\"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/main_dataset.xlsx\")\n",
    "JSON_OUTPUT_PATH = EXCEL_PATH.with_suffix(\".json\")\n",
    "\n",
    "def load_excel(file_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load Excel file to DataFrame.\"\"\"\n",
    "    return pd.read_excel(file_path)\n",
    "\n",
    "def dataframe_to_indexed_dict(df: pd.DataFrame, index_col: str = \"article_id\") -> dict:\n",
    "    \"\"\"Convert DataFrame to dict-of-dicts with specified index column.\"\"\"\n",
    "    if index_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{index_col}' not found in DataFrame columns: {df.columns.tolist()}\")\n",
    "    df = df.set_index(index_col)\n",
    "    return df.to_dict(orient=\"index\")\n",
    "\n",
    "def save_json(data: dict, file_path: Path) -> None:\n",
    "    \"\"\"Save dict to JSON.\"\"\"\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"âœ… JSON restored and saved to: {file_path}\")\n",
    "\n",
    "def main():\n",
    "    df = load_excel(EXCEL_PATH)\n",
    "    restored = dataframe_to_indexed_dict(df, index_col=\"article_id\")\n",
    "    save_json(restored, JSON_OUTPUT_PATH)\n",
    "\n",
    "    print(f\"ðŸ”‘ Total articles: {len(restored)}\")\n",
    "    print(f\"ðŸ“„ Fields in each article: {df.columns.tolist()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73b0fbf",
   "metadata": {},
   "source": [
    "Adding article id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48755487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done. Saved 29734 articles to '/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/main_data.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "input_path = \"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/main_data.json\"\n",
    "output_path = \"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/main_data.json\"\n",
    "\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "new_data = {}\n",
    "for idx, (url_key, article) in enumerate(data.items()):\n",
    "    new_data[str(idx)] = article \n",
    "\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… Done. Saved {len(new_data)} articles to '{output_path}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
