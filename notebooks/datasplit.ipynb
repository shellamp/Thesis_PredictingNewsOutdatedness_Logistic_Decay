{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438344b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Original t_bin counts:\n",
      "t_bin\n",
      "very_old      7900\n",
      "old           1555\n",
      "middle_age    1501\n",
      "recent         941\n",
      "fresh          580\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üéØ Target sample size per bin: 580\n",
      "\n",
      "üì¶ Final stratified bin counts:\n",
      "t_bin\n",
      "fresh         580\n",
      "recent        580\n",
      "middle_age    580\n",
      "old           580\n",
      "very_old      580\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Selected articles: 2900\n",
      "üóÇÔ∏è Remaining articles: 9577\n",
      "\n",
      "‚úÖ Saved selected to: /Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/finetuning/finetuning.json\n",
      "‚úÖ Saved remaining to: /Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/probability/probability.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "INPUT_PATH = \"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/main_dataset.json\"\n",
    "OUTPUT_PATH = \"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/finetuning/finetuning.json\"\n",
    "REMAINING_OUTPUT = \"/Users/sheillaschool/Documents/final/Thesis_PredictingNewsOutdatedness_LogisticDecay/data/main_data/probability/probability.json\"\n",
    "\n",
    "with open(INPUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame.from_dict(data, orient=\"index\").reset_index().rename(columns={\"index\": \"article_id\"})\n",
    "\n",
    "bin_counts = df[\"t_bin\"].value_counts()\n",
    "print(\"‚úÖ Original t_bin counts:\")\n",
    "print(bin_counts)\n",
    "\n",
    "target_count = bin_counts.min()\n",
    "print(f\"\\nüéØ Target sample size per bin: {target_count}\")\n",
    "\n",
    "selected_rows = []\n",
    "bin_order = [\"fresh\", \"recent\", \"middle_age\", \"old\", \"very_old\"]\n",
    "bins_to_use = [b for b in bin_order if b in df[\"t_bin\"].unique()]\n",
    "\n",
    "for bin_label in bins_to_use:\n",
    "    bin_df = df[df[\"t_bin\"] == bin_label].copy()\n",
    "    unique_t_df = bin_df.drop_duplicates(subset=\"t\")\n",
    "\n",
    "    if len(unique_t_df) >= target_count:\n",
    "        selected_bin = unique_t_df.sample(n=target_count, random_state=42)\n",
    "    else:\n",
    "        extra_needed = target_count - len(unique_t_df)\n",
    "        remaining = bin_df[~bin_df.index.isin(unique_t_df.index)]\n",
    "        fill = remaining.sample(n=min(extra_needed, len(remaining)), random_state=42)\n",
    "        selected_bin = pd.concat([unique_t_df, fill], ignore_index=True)\n",
    "\n",
    "    selected_rows.append(selected_bin)\n",
    "\n",
    "final_df = pd.concat(selected_rows).drop_duplicates(subset=\"article_id\").reset_index(drop=True)\n",
    "\n",
    "selected_ids = set(final_df[\"article_id\"])\n",
    "remaining_df = df[~df[\"article_id\"].isin(selected_ids)].copy().reset_index(drop=True)\n",
    "\n",
    "print(\"\\nüì¶ Final stratified bin counts:\")\n",
    "print(final_df[\"t_bin\"].value_counts())\n",
    "print(f\"\\n‚úÖ Selected articles: {len(final_df)}\")\n",
    "print(f\"üóÇÔ∏è Remaining articles: {len(remaining_df)}\")\n",
    "\n",
    "final_dict = {\n",
    "    str(row[\"article_id\"]): row.drop(labels=[\"article_id\"]).to_dict()\n",
    "    for _, row in final_df.iterrows()\n",
    "}\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_dict, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "remaining_dict = {\n",
    "    str(row[\"article_id\"]): row.drop(labels=[\"article_id\"]).to_dict()\n",
    "    for _, row in remaining_df.iterrows()\n",
    "}\n",
    "with open(REMAINING_OUTPUT, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(remaining_dict, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved selected to: {OUTPUT_PATH}\")\n",
    "print(f\"‚úÖ Saved remaining to: {REMAINING_OUTPUT}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
